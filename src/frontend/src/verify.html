<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Verification</title>
  </head>
  <body>
    <h1>Verify your identity to external apps</h1>
  </body>
</html>
<div id="step-2-content" class="step-content bg-gray-900 text-white mt-4 p-6 md:px-8 px-4 hidden ">
  <h3 class="mb-6 text-lg font-medium leading-none text-gray-100">Set Identity (KYC) .</h3>
  
  <div id="container" class="w-full md:max-w-lg mx-auto flex flex-col justify-center items-center">
    <h2 class="text-2xl font-bold mb-4 text-center text-green-400">Set Up Your Identity</h2>
    
    <div class="w-full  bg-gray-800 rounded-lg shadow-md ">
      <label id="filelabel" for="file" class="relative w-full border-2 border-blue-500 rounded-t-lg cursor-pointer">
        <div id="camera" class="relative">
          <video playsinline id="video" class="w-full h-auto sm:h-40 md:h-64 bg-gray-700 rounded-t-lg object-cover invisible"></video>
          <img id="image" class="hidden w-full h-auto sm:h-40 md:h-64 object-cover rounded-t-lg" src="logo_transparent.png" alt="Preview">
          <canvas id="canvas" class="hidden w-full h-8 invisible"></canvas>
          <input id="file" class="hidden" name="file" type="file" accept="image/png, image/jpeg">
        </div>
      </label>
      
      <div id="toolbar" class="w-full p-4 bg-gray-900">

   <div id="buttons" class="invisible w-full flex flex-col md:flex-row space-y-3 md:space-y-0 md:space-x-3 mt-2">
          <button id="recognize" class="w-full md:w-auto py-2 px-4 bg-green-500 text-white rounded-lg hover:bg-green-600 transition-colors">
            <i class="fa-solid fa-magnifying-glass mr-2"></i>Recognize face from document
          </button>
          <button id="store" class="w-full md:w-auto py-2 px-4 bg-green-500 text-white rounded-lg hover:bg-green-600 transition-colors">
            <i class="fa-solid fa-user mr-2"></i>Add face
          </button>
        </div>
        
        <div id="message" class="block w-full text-red-500 mt-4 break-words"></div>
        <button id="restart" class="invisible w-full py-2 px-4 bg-green-500 text-white rounded-lg mt-6 hover:bg-green-600 transition-colors invisible">
          <i class="fa-solid fa-rotate-right mr-2"></i>Back
        </button>
      </div>
    </div>
  </div>
  <div class="flex justify-between mt-4">
    <button
      type="button"
      id="step-2-prev"
      class="text-white bg-gray-700 hover:bg-gray-800 focus:ring-4 focus:outline-none focus:ring-gray-300 font-medium rounded-lg text-sm px-5 py-2.5 text-center"
    >
      Previous
    </button>
    <button
      type="button"
      id="step-2-next"
      class="text-white bg-blue-700 hover:bg-blue-800 focus:ring-4 focus:outline-none focus:ring-blue-300 font-medium rounded-lg text-sm px-5 py-2.5 text-center bg-blue-600 hover:bg-blue-700 focus:ring-blue-800"
    >
      Next Step: Verify KYC
    </button>
  </div>
</div>

<script>
  window.onload = async () => {
    elem("recognize").onclick = recognize;
    elem("store").onclick = store;
    elem("file").onchange = load_local_image;
    elem("canvas").onclick = restart;
    elem("restart").onclick = restart;
    elem("video").oncanplay = () => {
      show("video");
      hide("image");
      hide("canvas");
    };
  
    navigator.mediaDevices
      .getUserMedia({ video: true, audio: false })
      .then((stream) => {
        const video = elem("video");
        video.srcObject = stream;
        video.play();
        show("buttons");
      })
      .catch((err) => {
        show("image");
        hide("buttons");
        hide("video");
        hide("canvas");
        console.error(`An error occurred: ${err}`);
        message("Couldn't start camera, but you can upload photos.");
      });
  };
  
  // Returns a DOM element that is currently visible and contains an image.
  function select_visible_element() {
    const video = elem("video");
    const image = elem("image");
    const canvas = elem("canvas");
    if (!video.className.includes("invisible")) {
      return [video, video.videoWidth, video.videoHeight];
    } else if (!image.className.includes("invisible")) {
      return [image, image.width, image.height];
    } else {
      return [canvas, canvas.width, canvas.height];
    }
  }
  
  // Captures the image from the camera stream or from the image element or from
  // the canvas element depending on which one of them is visible.
  //
  // It also scales the image down to 320x240px such that it can be submitted to
  // the backend for face detection.
  async function capture_image() {
    let [image, width, height] = select_visible_element();
  
    const canvas = elem("canvas");
    canvas.width = width;
    canvas.height = height;
    const context = canvas.getContext("2d");
    context.drawImage(image, 0, 0, width, height);
  
    const resized = document.createElement("canvas");
    resized.width = 320;
    resized.height = 240;
    let scale = Math.min(
      resized.width / canvas.width,
      resized.height / canvas.height
    );
    width = canvas.width * scale;
    height = canvas.height * scale;
    let x = resized.width / 2 - width / 2;
    let y = resized.height / 2 - height / 2;
    const ctx = resized.getContext("2d");
    if (ctx) {
      ctx.drawImage(canvas, x, y, width, height);
    }
    let bytes = await serialize(resized);
  
    if (video.srcObject) {
      video.srcObject.getTracks().forEach((track) => track.stop());
    }
  
    hide("video");
    hide("image");
    show("canvas");
    return [bytes, { scale, x, y }];
  }
  
  // Renders the bounding box around the face and also returns a small image of
  // the face that can be submitted to the backend for recognition.
  async function render(scaling, box) {
    box.left = Math.round((box.left * 320 - scaling.x) / scaling.scale);
    box.right = Math.round((box.right * 320 - scaling.x) / scaling.scale);
    box.top = Math.round((box.top * 240 - scaling.y) / scaling.scale);
    box.bottom = Math.round((box.bottom * 240 - scaling.y) / scaling.scale);
  
    const canvas = elem("canvas");
  
    const small = document.createElement("canvas");
    small.width = 160;
    small.height = 160;
    const ctx2 = small.getContext("2d");
    if (ctx2) {
      ctx2.drawImage(
        canvas,
        box.left,
        box.top,
        box.right - box.left,
        box.bottom - box.top,
        0,
        0,
        140,
        140
      );
    }
    let bytes = await serialize(small);
  
    const ctx = canvas.getContext("2d");
    if (ctx) {
      ctx.strokeStyle = "#0f3";
      ctx.lineWidth = 5;
      ctx.beginPath();
      ctx.rect(box.left, box.top, box.right - box.left, box.bottom - box.top);
      ctx.stroke();
    }
  
    return bytes;
  }
  
  // This function performs the following steps:
  // 1. Capture the image from the camera stream (or from the local file).
  // 2. Call the backend to detect the bounding box of the face in the image.
  // 3. Call the backend to recognize the face.
  async function recognize(event) {
    event.preventDefault();
    hide("buttons");
    show("loader");
    message("Detecting face..");
    try {
      const [blob, scaling] = await capture_image();
      let result;
      result = await backend.detect(new Uint8Array(blob));
      if (!result.Ok) {
        throw result.Err.message;
      }
      let face = await render(scaling, result.Ok);
      message("Face detected. Recognizing..");
      result = await backend.recognize(new Uint8Array(face));
      if (!result.Ok) {
        throw result.Err.message;
      }
      let label = sanitize(result.Ok.label);
      let score = Math.round(result.Ok.score * 100) / 100;
      message(
        `The face in the document matched with your face, here is your identity please copy and store it safely, ${label}, difference=${score}`
      );
    } catch (err) {
      console.error(`An error occurred: ${err}`);
      message(err.toString());
    }
    hide("loader");
    show("restart");
    return false;
  }
  
  // This function performs the following steps:
  // 1. Capture the image from the camera stream (or from the local file).
  // 2. Call the backend to detect the bounding box of the face in the image.
  // 3. Ask the user for their name.
  // 4. Call the backend to store the image and the name of the user.
  async function store(event) {
    event.preventDefault();
    hide("buttons");
    show("loader");
    message("Detecting face..");
    try {
      const [blob, scaling] = await capture_image();
      let result;
      result = await backend.detect(new Uint8Array(blob));
      if (!result.Ok) {
        throw result.Err.message;
      }
      let face = await render(scaling, result.Ok);
      message("Face detected. Adding..");
      let label = prompt("Enter name of the person");
      if (!label) {
        throw "cannot add without a name";
      }
      label = sanitize(label);
      message(`Face detected. Adding ${label}..`);
      result = await backend.add(label, new Uint8Array(face));
      if (!result.Ok) {
        throw result.Err.message;
      }
      message(`Successfully added ${label}.`);
    } catch (err) {
      console.error(`An error occurred: ${err}`);
      message("Failed to add the face: " + err.toString());
    }
  
    hide("loader");
    show("restart");
    return false;
  }
  
  // Invoked when a file is selected in the file input element.
  // Loads the given file as an image to show to the user.
  async function load_local_image(event) {
    message("");
    let image = elem("image");
    try {
      const file = event.target.files[0];
      if (!file) {
        return false;
      }
      const url = await toDataURL(file);
      image.src = url;
    } catch (err) {
      message("Failed to select photo: " + err.toString());
    }
    hide("video");
    hide("canvas");
    show("image");
    show("buttons");
    return false;
  }
  
  // Converts the given blob into a data url such that it can be assigned as a
  // target of a link of as an image source.
  function toDataURL(blob) {
    return new Promise((resolve, _) => {
      const fileReader = new FileReader();
      fileReader.readAsDataURL(blob);
      fileReader.onloadend = function () {
        resolve(fileReader.result);
      };
    });
  }
  
  // Restarts the face recognition / addition user flow.
  async function restart(event) {
    hide("restart");
    message("");
    if (video.srcObject) {
      event.preventDefault();
    }
    navigator.mediaDevices
      .getUserMedia({ video: true, audio: false })
      .then((stream) => {
        const video = elem("video");
        video.srcObject = stream;
        video.play();
        show("buttons");
      });
  }
  
  // Returns a DOM element by its id.
  function elem(id) {
    return document.getElementById(id);
  }
  
  // Makes the given DOM element visible.
  function show(id) {
    elem(id).className = "";
  }
  
  // Makes the given DOM element invisible.
  function hide(id) {
    elem(id).className = "invisible";
  }
  
  // Sets the message element's text to the given text.
  function message(m) {
    elem("message").innerText = m;
  }
  
  // Returns an PNG image from the canvas.
  function serialize(canvas) {
    return new Promise((resolve) =>
      canvas.toBlob((blob) => blob.arrayBuffer().then(resolve), "image/png", 0.9)
    );
  }
  
  // Sanitizes the name string by filtering out characters that are not letters,
  // numbers, spaces, and dashes.
  function sanitize(name) {
    return name.match(/[\p{L}\p{N}\s_-]/gu).join("");
  }</script>









<div id="container" style="margin: 0; width: 100%; padding: 0;" class="hidden md:max-w-md  mx-auto  flex flex-col justify-center items-center   w-full overflow-hidden">
  <h2 class="text-2xl font-bold mb-6 text-center text-green-700">Set Up Your Identity</h2>
  <div style="margin: 0; width: 100%; padding: 0;" class="w-full   ">
    <div style="margin: 0; width: 100%; padding: 0;" class=" bg-red-500 h-auto w-full">
      <label id="filelabel" for="file" class=" border border-blue-500  relative  w-full mb-0">
        <div id="camera" class=" relative  ">
           <video playsinline id="video" class=" invisible w-full h-auto sm:h-40 md:h-64 bg-gray-100 rounded-t-lg object-cover "> </video>
          <!-- <video id="video" class="  w-full h-auto sm:h-40 md:h-64 bg-gray-100 rounded-t-lg object-cover invisible"></video> -->
          <img id="image" class="  hidden  h-auto sm:h-40 md:h-64 object-cover rounded-t-lg" src="logo_transparent.png" alt="Preview">
          <canvas id="canvas" class=" hidden w-full   h-8 invisible"></canvas>
          <input id="file" class="hidden" name="file" type="file" accept="image/png, image/jpeg">
        </div>
      </label>
      <!-- <div>
        <img id="loader" src="loader.svg" class="invisible" />
      </div>  -->

      <div id="toolbar" class=" w-full p-4 flex flex-col  mt-0 ">
     
        <div id="buttons" class="w-full invisible flex flex-col md:flex-row ">
          <button id="recognize" class="  w-full sm:w-auto py-2 md:px-4 bg-green-500 text-white rounded-lg hover:bg-green-600 transition-colors">
            <i class="fa-solid fa-magnifying-glass mr-2"></i>Recognize face from document
          </button>
          <button id="store" class=" w-full sm:w-auto py-2 px-4 bg-green-500 text-white rounded-lg hover:bg-green-600 transition-colors">
            <i class="fa-solid fa-user mr-2"></i>Add face
          </button>
        </div>
        
        <div id="message" class="block w-full  text-red-500  break-words "></div>
        <button id="restart" class=" invisible w-full py-2 px-4 bg-green-500 text-white rounded-lg  mt-6 hover:bg-green-600 transition-colors">
          <i class="fa-solid fa-rotate-right mr-2"></i>Back
        </button>
      </div>
    </div>
  </div>
</div> -->
